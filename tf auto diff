import tensorflow as tf
w = tf.Variable(3.0)
x = 1.0
y = 1.0
alpha = 0.01
iterations = 300
for iter in range(iterations):
    with tf.GradientTape() as tape:
        fwb = w*x
        costJ = (fwb - y)**2
    [djdw] = tape.gradient( costJ, [w] )
    w.assign_add( -alpha * djdw )
    print(w)
    print([djdw])

# with optimizer
import keras.optimizers
import tensorflow as tf
optimizer = keras.optimizers.Adam(learning_rate=1e-1)


iterations = 200
for iter in range(iterations):
    with tf.GradientTape() as tape:
        cost_value = confiCostFuncV(X, W, b, Ynorm, R, num_users, num_movies, lambda )
    grades = tape.gradient( cost_value, [X,W,b] )
    optimizer.apply_gradients(zip(grades,[X,W,b]))
